{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1815239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import sys\n",
    "from imutils import paths\n",
    "import logging\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = os.path.basename(__name__)\n",
    "path_arr = os.getcwd().split(os.path.sep)\n",
    "os.chdir(os.path.sep.join(path_arr[:path_arr.index('src')+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger global variable\n",
    "def create_logger(logs_path,script_name,level='INFO'):\n",
    "\n",
    "    if not os.path.exists(logs_path):\n",
    "        os.makedirs(logs_path)\n",
    "\n",
    "    datetime_for_name = datetime.now().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "    file_name = os.path.join(logs_path, f'{script_name}_{datetime_for_name}.log')\n",
    "    \n",
    "    global logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    while len(logger.handlers) > 0:\n",
    "        h = logger.handlers[0]\n",
    "        logger.removeHandler(h)\n",
    "    \n",
    "    if level.lower().startswith('critical'):\n",
    "        l = logging.CRITICAL\n",
    "    elif level.lower().startswith('error'):\n",
    "        l = logging.ERROR\n",
    "    elif level.lower().startswith('warning'):\n",
    "        l = logging.WARNING\n",
    "    elif level.lower().startswith('info'):\n",
    "        l = logging.INFO\n",
    "    elif level.lower().startswith('debug'):\n",
    "        l = logging.DEBUG\n",
    "    else:\n",
    "        l = logging.INFO\n",
    "        \n",
    "    formatter = logging.Formatter('%(asctime)s - %(funcName)s - %(levelname)s - %(message)s')\n",
    "        \n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "    \n",
    "    fh = logging.FileHandler(file_name)\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    \n",
    "    logger.setLevel(l)\n",
    "    \n",
    "    logger.info('Log created propperly.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs_from_image(img_path, opencv_dnn_model,embedder,multiple_faces = False, min_confidence=0.9, display=False):\n",
    "\n",
    "    logger.debug(f'Starting face detection. Multiple faces: {multiple_faces}. Minimun confidence: {min_confidence}. Display mode: {display}')\n",
    "    scanned_faces = 0\n",
    "    embeddings = []\n",
    "    admited_file_types = ['jpeg','png','webp',None]\n",
    "    file_format = imghdr.what(img_path)\n",
    "\n",
    "    if file_format not in admited_file_types:\n",
    "        raise ValueError('The image provided is not withing the admited file formats',file_format)\n",
    "                              \n",
    "    image = cv2.imread(img_path)\n",
    "    image = imutils.resize(image, width=600)\n",
    "    h, w, _ = image.shape\n",
    "    output_image = image.copy()\n",
    "    logger.debug(f'Converting image to blob...')\n",
    "    preprocessed_image = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300), mean=(104.0, 117.0, 123.0), swapRB=False, crop=False)\n",
    "    \n",
    "    opencv_dnn_model.setInput(preprocessed_image)\n",
    "\n",
    "    logger.debug(f'Scanning image...')\n",
    "    scan_start = time()\n",
    "    results = opencv_dnn_model.forward()    \n",
    "    scan_end = time()\n",
    "    scan_time = str(scan_end - scan_start)\n",
    "    logger.debug(f'Scanning complete. Exec time: {scan_time} seconds.')\n",
    "        \n",
    "    i = np.argmax(results[0, 0, :, 2])\n",
    "    iteration = 0\n",
    "    \n",
    "    for face in results[0][0]:\n",
    "        if not multiple_faces:\n",
    "            if iteration != i:\n",
    "                continue\n",
    "        \n",
    "        iteration+=1\n",
    "        face_confidence = face[2]\n",
    "\n",
    "        if face_confidence > min_confidence:\n",
    "            \n",
    "            logger.debug(f'Scanning face {iteration}. Face confidence: {face_confidence}.')\n",
    "            \n",
    "            # compute the (x, y)-coordinates of the bounding box for the face\n",
    "            box = face[3:7] * np.array([w, h, w, h])\n",
    "            (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "\n",
    "            # extract the face ROI and grab the ROI dimensions\n",
    "            face_roi = image[y1:y2, x1:x2]\n",
    "            (fH, fW) = face_roi.shape[:2]\n",
    "\n",
    "            # ensure the face width and height are sufficiently large\n",
    "            if fW < 20 or fH < 20:\n",
    "                logger.debug(f'Face {iteration} didnt meet minimun size requirements, we are moving to the next one.')\n",
    "                continue\n",
    "\n",
    "            # construct a blob for the face ROI, then pass the blob through our face embedding model to obtain the 128-d quantification of the face\n",
    "            faceBlob = cv2.dnn.blobFromImage(face_roi, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "            embedder.setInput(faceBlob)\n",
    "            \n",
    "            logger.debug(f'Processing image {iteration}...')\n",
    "            emb_start = time()\n",
    "            vec = embedder.forward()\n",
    "            emb_end = time()\n",
    "            emb_time = str(emb_end - emb_start)\n",
    "            logger.debug(f'Processing completed. Exec time : {emb_time} seconds.')\n",
    "            \n",
    "            embeddings.append(vec.flatten())\n",
    "            scanned_faces+=1 \n",
    "            \n",
    "            if display:\n",
    "                cv2.rectangle(output_image, pt1=(x1, y1), pt2=(x2, y2), color=(0, 255, 0), thickness=w//200)\n",
    "    \n",
    "    logger.debug(f'Scan completed. Total faces scanned: {str(scanned_faces)}.')\n",
    "    \n",
    "    if display:\n",
    "        plt.figure(figsize=[20,20])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output\");plt.axis('off');\n",
    "        \n",
    "    else:\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_index(image_path):\n",
    "    return int(image_path.split(os.path.sep)[-1].split('.')[0].split('_')[-1])\n",
    "\n",
    "def get_actors_dict(actor_faces_folder):\n",
    "    image_paths = list(paths.list_images(actor_faces_folder))\n",
    "    actors_dict = {}\n",
    "    \n",
    "    for (i, image_path) in enumerate(image_paths):\n",
    "        actor_name = image_path.split(os.path.sep)[3]\n",
    "\n",
    "        if actor_name not in actors_dict.keys():\n",
    "            actors_dict[actor_name] = []\n",
    "\n",
    "        actors_dict[actor_name].append(image_path)\n",
    "        \n",
    "    for actor, actors_images in actors_dict.items():\n",
    "        actors_images.sort(key = path_index)\n",
    "    \n",
    "    return(actors_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9daa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actors_embs(actor_faces_folder,images_per_actor = None):\n",
    "    process_start = time()\n",
    "    actors_dict = get_actors_dict(actor_faces_folder)\n",
    "    logger.info(f'Totals actors retrieved: {len(actors_dict)}.')\n",
    "    \n",
    "    protoPath = './models/face_detector/deploy.prototxt'\n",
    "    modelPath = './models/face_detector/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "    embeddingPath = './models/face_detector/openface.nn4.small2.v1.t7'\n",
    "    detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "    embedder = cv2.dnn.readNetFromTorch(embeddingPath)\n",
    "    \n",
    "    actors_names = []\n",
    "    actors_embeddings = []\n",
    "    \n",
    "    for actor, actors_images in actors_dict.items():\n",
    "        processed_images = 0\n",
    "        if images_per_actor is None:\n",
    "            images_per_actor = len(actors_images)\n",
    "        \n",
    "        logger.info(f'Analyzing actor {actor}. Total images available: {len(actors_images)}. Images to process: {images_per_actor}')\n",
    "        \n",
    "        for (i, img_path) in enumerate(actors_images):\n",
    "            if i + 1 > images_per_actor:\n",
    "                continue\n",
    "            \n",
    "            logger.debug(f'Getting embeddings for image {i+1}/{images_per_actor} for actor {actor}.')\n",
    "            try:\n",
    "                img_embeddings = get_embs_from_image(img_path,detector,embedder)\n",
    "            except ValueError as err:\n",
    "                logger.error(err)\n",
    "                continue\n",
    "\n",
    "            if len(img_embeddings) == 1:\n",
    "                if len(img_embeddings[0]) == 128:\n",
    "                    processed_images+=1\n",
    "                    actors_names.append(actor)\n",
    "                    actors_embeddings.append(img_embeddings)\n",
    "            else:\n",
    "                logger.debug(\"embedding is not 128\")\n",
    "                continue             \n",
    "            \n",
    "            \n",
    "        logger.info(f'{processed_images}/{images_per_actor} images for actor {actor} were processed.')\n",
    "        images_per_actor = None\n",
    "\n",
    "    emb_dict = {\"embeddings\": actors_embeddings, \"names\": actors_names}\n",
    "    process_end = time()\n",
    "    process_time = str(process_end - process_start)\n",
    "    logger.info(f'Embedding extraction finished. Exec time: {process_time}.')\n",
    "    return emb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2e5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b71549",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_logger('./models/logs',script_name,level='info')\n",
    "embeddings = get_actors_embs('./datasets/actor_faces')\n",
    "f = open('./models/embeddings/embeddings.pickle', \"wb\")\n",
    "f.write(pickle.dumps(embeddings))\n",
    "f.close()\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dab38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger = create_logger('./models/logs',script_name,level='info')\n",
    "protoPath = './models/face_detector/deploy.prototxt'\n",
    "modelPath = './models/face_detector/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "embeddingPath = './models/face_detector/openface.nn4.small2.v1.t7'\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "embedder = cv2.dnn.readNetFromTorch(embeddingPath)\n",
    "img_path = './datasets/actor_faces/2037_cillian_murphy/cillian_murphy_inception_1.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "get_embs_from_image(img,detector,embedder,display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa747470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for array in embeddings[\"embeddings\"]:\n",
    "    print(len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings[\"embeddings\"][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bacf09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[\"names\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4e74b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
