{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import sys\n",
    "#!{sys.executable} -m pip install imutils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#!{sys.executable} -m pip install dlib\n",
    "#import dlib\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our serialized face detector from disk\n",
    "protoPath = '/opt/workspace/src/models/face_detector/deploy.prototxt'\n",
    "modelPath = '/opt/workspace/src/models/face_detector/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "embeddingPath = '/opt/workspace/src/models/face_detector/openface.nn4.small2.v1.t7'\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "embedder = cv2.dnn.readNetFromTorch(embeddingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_person = '/opt/workspace/src/datasets/actor_faces/2037_cillian_murphy/cillian_murphy_1.jpg'\n",
    "two_person = '/opt/workspace/src/datasets/two_people.jpeg'\n",
    "original_image = cv2.imread(two_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvDnnDetectFaces(image, opencv_dnn_model,multiple_faces = False, min_confidence=0.9, display=False):\n",
    "\n",
    "    scanned_faces = 0\n",
    "    embeddings = []\n",
    "    image = imutils.resize(image, width=600)\n",
    "    h, w, _ = image.shape\n",
    "    output_image = image.copy()\n",
    "    preprocessed_image = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300), mean=(104.0, 117.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "    opencv_dnn_model.setInput(preprocessed_image)\n",
    "\n",
    "    scan_start = time()\n",
    "    results = opencv_dnn_model.forward()    \n",
    "    scan_end = time()\n",
    "    scan_time = str(scan_end - scan_start)\n",
    "    if display:\n",
    "        print(f'Time taken to scan the image: {scan_time} seconds.')\n",
    "        \n",
    "    i = np.argmax(results[0, 0, :, 2])\n",
    "    iteration = 0\n",
    "    \n",
    "    for face in results[0][0]:\n",
    "        if not multiple_faces:\n",
    "            if iteration != i:\n",
    "                continue\n",
    "        \n",
    "        iteration+=1\n",
    "\n",
    "        face_confidence = face[2]\n",
    "\n",
    "        if face_confidence > min_confidence:\n",
    "            \n",
    "            # compute the (x, y)-coordinates of the bounding box for the face\n",
    "            box = face[3:7] * np.array([w, h, w, h])\n",
    "            (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "\n",
    "            # extract the face ROI and grab the ROI dimensions\n",
    "            face_roi = image[y1:y2, x1:x2]\n",
    "            (fH, fW) = face_roi.shape[:2]\n",
    "\n",
    "            # ensure the face width and height are sufficiently large\n",
    "            if fW < 20 or fH < 20:\n",
    "                continue\n",
    "                \n",
    "            scanned_faces+=1 \n",
    "\n",
    "            # construct a blob for the face ROI, then pass the blob through our face embedding model to obtain the 128-d quantification of the face\n",
    "            faceBlob = cv2.dnn.blobFromImage(face_roi, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "            embedder.setInput(faceBlob)\n",
    "            \n",
    "            emb_start = time()\n",
    "            vec = embedder.forward()\n",
    "            emb_end = time()\n",
    "            emb_time = str(emb_end - emb_start)\n",
    "            \n",
    "            embeddings.append(vec[0])\n",
    "            \n",
    "            if display:\n",
    "                print(f'Time taken to process face : {emb_time} seconds.')\n",
    "                cv2.rectangle(output_image, pt1=(x1, y1), pt2=(x2, y2), color=(0, 255, 0), thickness=w//200)\n",
    "    \n",
    "    if display:\n",
    "        print(f'Total faces scanned: {str(scanned_faces)} ')\n",
    "        plt.figure(figsize=[20,20])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output\");plt.axis('off');\n",
    "        \n",
    "    else:\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ad9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = cvDnnDetectFaces(original_image,detector,multiple_faces = True, display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b27c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93963c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the facial embeddings + names to disk\n",
    "print(\"[INFO] serializing {} encodings...\".format(total))\n",
    "data = {\"embeddings\": knownEmbeddings, \"names\": knownNames}\n",
    "f = open('/opt/workspace/src/models/results/, \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
